"""
WorkeråŒæ­¥æœåŠ¡
"""
import asyncio
import logging
from typing import Dict, Any, List, Optional
import httpx
from datetime import datetime

from src.config import settings
from src.services.stats_service import StatsService
from src.models.logs import SyncLog
from src.database import get_db_sync

logger = logging.getLogger(__name__)

class WorkerSyncService:
    """WorkeråŒæ­¥æœåŠ¡ç±»"""
    
    def __init__(self):
        self.stats_service = StatsService()
        self.db = get_db_sync
        
        # HTTPå®¢æˆ·ç«¯é…ç½®
        self.client_config = {
            "timeout": httpx.Timeout(settings.SYNC_TIMEOUT_SECONDS),
            "limits": httpx.Limits(max_connections=10, max_keepalive_connections=5)
        }
    
    async def push_config_to_worker(self, worker_endpoint: str, config_data: Dict[str, Any]) -> bool:
        """æ¨é€é…ç½®åˆ°Worker"""
        sync_log = None
        
        try:
            # åˆ›å»ºåŒæ­¥æ—¥å¿—
            sync_log = await self._create_sync_log(
                worker_endpoint, "config", "push", len(str(config_data))
            )
            
            logger.info(f"ğŸ”„ å¼€å§‹æ¨é€é…ç½®åˆ°Worker: {worker_endpoint}")
            
            async with httpx.AsyncClient(**self.client_config) as client:
                # æ„å»ºæ¨é€URL
                push_url = f"{worker_endpoint.rstrip('/')}/worker-api/config/update"
                
                # è·å–APIå¯†é’¥
                from src.services.config_manager import config_manager
                api_key = config_manager.get_data_center_api_key()

                logger.info(f"ğŸ”‘ æ•°æ®ä¸­å¿ƒå‘Workeræ¨é€é…ç½®:")
                logger.info(f"   - Workerç«¯ç‚¹: {worker_endpoint}")
                logger.info(f"   - API Key: {api_key[:8] + '...' if api_key else 'æœªé…ç½®'}")
                logger.info(f"   - API Keyé•¿åº¦: {len(api_key) if api_key else 0}")

                # æ„å»ºè¯·æ±‚å¤´
                headers = {
                    "Content-Type": "application/json",
                    "User-Agent": "DataCenter-Sync/1.0"
                }

                if api_key:
                    headers["X-API-Key"] = api_key
                    logger.info(f"âœ… å·²æ·»åŠ X-API-Keyå¤´éƒ¨")
                else:
                    logger.warning(f"âš ï¸ æœªé…ç½®API Keyï¼Œè¯·æ±‚å°†ä¸åŒ…å«X-API-Keyå¤´éƒ¨")

                # å‘é€é…ç½®æ•°æ®
                response = await client.post(
                    push_url,
                    json={
                        "ua_configs": config_data.get("ua_configs", {}),
                        "ip_blacklist": config_data.get("ip_blacklist", {}),
                        "timestamp": datetime.now().isoformat()
                    },
                    headers=headers
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get("success"):
                        logger.info(f"âœ… é…ç½®æ¨é€æˆåŠŸ: {worker_endpoint}")
                        await self._complete_sync_log(sync_log, "success")
                        return True
                    else:
                        error_msg = result.get("error", "Unknown error")
                        logger.error(f"âŒ Workerè¿”å›é”™è¯¯: {error_msg}")
                        await self._complete_sync_log(sync_log, "failed", error_msg)
                        return False
                else:
                    error_msg = f"HTTP {response.status_code}: {response.text}"
                    logger.error(f"âŒ é…ç½®æ¨é€å¤±è´¥: {error_msg}")
                    await self._complete_sync_log(sync_log, "failed", error_msg)
                    return False
                    
        except httpx.TimeoutException:
            error_msg = f"æ¨é€é…ç½®è¶…æ—¶: {worker_endpoint}"
            logger.error(f"âŒ {error_msg}")
            if sync_log:
                await self._complete_sync_log(sync_log, "timeout", error_msg)
            return False
            
        except Exception as e:
            error_msg = f"æ¨é€é…ç½®å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            if sync_log:
                await self._complete_sync_log(sync_log, "error", error_msg)
            return False
    
    async def pull_stats_from_worker(self, worker_endpoint: str) -> Optional[Dict[str, Any]]:
        """ä»Workeræ‹‰å–ç»Ÿè®¡æ•°æ®"""
        sync_log = None
        
        try:
            # åˆ›å»ºåŒæ­¥æ—¥å¿—
            sync_log = await self._create_sync_log(
                worker_endpoint, "stats", "pull", 0
            )
            
            logger.info(f"ğŸ“Š å¼€å§‹ä»Workeræ‹‰å–ç»Ÿè®¡: {worker_endpoint}")
            
            async with httpx.AsyncClient(**self.client_config) as client:
                # æ„å»ºæ‹‰å–URL
                stats_url = f"{worker_endpoint.rstrip('/')}/worker-api/stats"

                # è·å–APIå¯†é’¥
                from src.services.config_manager import config_manager
                api_key = config_manager.get_data_center_api_key()

                logger.info(f"ğŸ“Š æ•°æ®ä¸­å¿ƒå‘Workeræ‹‰å–ç»Ÿè®¡:")
                logger.info(f"   - Workerç«¯ç‚¹: {worker_endpoint}")
                logger.info(f"   - API Key: {api_key[:8] + '...' if api_key else 'æœªé…ç½®'}")
                logger.info(f"   - API Keyé•¿åº¦: {len(api_key) if api_key else 0}")

                # æ„å»ºè¯·æ±‚å¤´
                headers = {"User-Agent": "DataCenter-Sync/1.0"}
                if api_key:
                    headers["X-API-Key"] = api_key
                    logger.info(f"âœ… å·²æ·»åŠ X-API-Keyå¤´éƒ¨")
                else:
                    logger.warning(f"âš ï¸ æœªé…ç½®API Keyï¼Œè¯·æ±‚å°†ä¸åŒ…å«X-API-Keyå¤´éƒ¨")

                response = await client.get(stats_url, headers=headers)
                
                if response.status_code == 200:
                    stats_data = response.json()
                    logger.info(f"âœ… ç»Ÿè®¡æ•°æ®æ‹‰å–æˆåŠŸ: {worker_endpoint}")
                    
                    # æ›´æ–°åŒæ­¥æ—¥å¿—
                    data_size = len(response.content)
                    records_count = len(stats_data.get("request_stats", []))
                    await self._complete_sync_log(sync_log, "success", data_size=data_size, records_count=records_count)
                    
                    return stats_data
                else:
                    error_msg = f"HTTP {response.status_code}: {response.text}"
                    logger.error(f"âŒ ç»Ÿè®¡æ‹‰å–å¤±è´¥: {error_msg}")
                    await self._complete_sync_log(sync_log, "failed", error_msg)
                    return None
                    
        except httpx.TimeoutException:
            error_msg = f"æ‹‰å–ç»Ÿè®¡è¶…æ—¶: {worker_endpoint}"
            logger.error(f"âŒ {error_msg}")
            if sync_log:
                await self._complete_sync_log(sync_log, "timeout", error_msg)
            return None
            
        except Exception as e:
            error_msg = f"æ‹‰å–ç»Ÿè®¡å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            if sync_log:
                await self._complete_sync_log(sync_log, "error", error_msg)
            return None
    
    async def sync_all_workers(self, config_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŒæ­¥æ‰€æœ‰Worker"""
        results = {
            "total_workers": 0,
            "success_count": 0,
            "failed_count": 0,
            "results": []
        }
        
        worker_endpoints = settings.WORKER_ENDPOINTS
        if not worker_endpoints:
            logger.warning("âš ï¸ æœªé…ç½®Workerç«¯ç‚¹")
            return results
        
        results["total_workers"] = len(worker_endpoints)
        
        # å¹¶å‘åŒæ­¥æ‰€æœ‰Worker
        tasks = []
        for endpoint in worker_endpoints:
            task = self._sync_single_worker(endpoint, config_data)
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        sync_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        for i, result in enumerate(sync_results):
            endpoint = worker_endpoints[i]
            
            if isinstance(result, Exception):
                results["failed_count"] += 1
                results["results"].append({
                    "endpoint": endpoint,
                    "success": False,
                    "error": str(result)
                })
            elif result:
                results["success_count"] += 1
                results["results"].append({
                    "endpoint": endpoint,
                    "success": True
                })
            else:
                results["failed_count"] += 1
                results["results"].append({
                    "endpoint": endpoint,
                    "success": False,
                    "error": "Unknown error"
                })
        
        logger.info(f"ğŸ“Š WorkeråŒæ­¥å®Œæˆ: {results['success_count']}/{results['total_workers']} æˆåŠŸ")
        return results
    
    async def _sync_single_worker(self, endpoint: str, config_data: Dict[str, Any]) -> bool:
        """åŒæ­¥å•ä¸ªWorker"""
        try:
            # æ¨é€é…ç½®
            config_success = await self.push_config_to_worker(endpoint, config_data)
            
            # æ‹‰å–ç»Ÿè®¡ï¼ˆå¯é€‰ï¼‰
            stats_data = await self.pull_stats_from_worker(endpoint)
            
            # å¦‚æœæ‹‰å–åˆ°ç»Ÿè®¡æ•°æ®ï¼Œä¿å­˜åˆ°æ•°æ®åº“
            if stats_data:
                await self._save_worker_stats(endpoint, stats_data)
            
            return config_success
            
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥Worker {endpoint} å¼‚å¸¸: {e}")
            return False
    
    async def _save_worker_stats(self, worker_endpoint: str, stats_data: Dict[str, Any]) -> bool:
        """ä¿å­˜Workerç»Ÿè®¡æ•°æ®"""
        try:
            # æå–Worker ID
            worker_id = worker_endpoint.split("//")[-1].split("/")[0]  # ä»URLæå–åŸŸåä½œä¸ºID
            
            # ä¿å­˜è¯·æ±‚ç»Ÿè®¡
            request_stats = stats_data.get("request_stats", {})
            if request_stats:
                await self.stats_service.record_worker_stats(worker_id, request_stats)
            
            # ä¿å­˜å…¶ä»–ç»Ÿè®¡æ•°æ®...
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•æ›´å¤šç»Ÿè®¡æ•°æ®çš„ä¿å­˜é€»è¾‘
            
            logger.info(f"âœ… Workerç»Ÿè®¡æ•°æ®ä¿å­˜æˆåŠŸ: {worker_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜Workerç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            return False
    
    async def _create_sync_log(self, worker_endpoint: str, sync_type: str, direction: str, data_size: int = 0) -> Optional[SyncLog]:
        """åˆ›å»ºåŒæ­¥æ—¥å¿—"""
        try:
            db = self.db()
            
            # æå–Worker ID
            worker_id = worker_endpoint.split("//")[-1].split("/")[0]
            
            sync_log = SyncLog(
                worker_id=worker_id,
                sync_type=sync_type,
                direction=direction,
                status="pending",
                data_size=data_size,
                started_at=datetime.now()
            )
            
            db.add(sync_log)
            db.commit()
            db.refresh(sync_log)
            db.close()
            
            return sync_log
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåŒæ­¥æ—¥å¿—å¤±è´¥: {e}")
            return None
    
    async def _complete_sync_log(self, sync_log: SyncLog, status: str, error_message: str = None, 
                                data_size: int = None, records_count: int = None):
        """å®ŒæˆåŒæ­¥æ—¥å¿—"""
        try:
            if not sync_log:
                return
            
            db = self.db()
            
            # é‡æ–°æŸ¥è¯¢æ—¥å¿—å¯¹è±¡ï¼ˆé¿å…ä¼šè¯é—®é¢˜ï¼‰
            log = db.query(SyncLog).filter(SyncLog.id == sync_log.id).first()
            if not log:
                db.close()
                return
            
            # æ›´æ–°æ—¥å¿—çŠ¶æ€
            log.status = status
            log.completed_at = datetime.now()
            log.duration = int((log.completed_at - log.started_at).total_seconds() * 1000)
            
            if error_message:
                log.error_message = error_message
            
            if data_size is not None:
                log.data_size = data_size
            
            if records_count is not None:
                log.records_count = records_count
            
            db.commit()
            db.close()
            
        except Exception as e:
            logger.error(f"å®ŒæˆåŒæ­¥æ—¥å¿—å¤±è´¥: {e}")

    async def process_worker_logs(self, worker_id: str, logs_data: List[Dict[str, Any]]) -> bool:
        """å¤„ç†Workeræ¨é€çš„æ—¥å¿—æ•°æ®"""
        try:
            if not logs_data:
                logger.info(f"Worker {worker_id} æ²¡æœ‰æ—¥å¿—æ•°æ®")
                return True

            logger.info(f"å¼€å§‹å¤„ç†Worker {worker_id} çš„ {len(logs_data)} æ¡æ—¥å¿—")
            logger.debug(f"æ—¥å¿—æ•°æ®ç¤ºä¾‹: {logs_data[:2] if len(logs_data) > 0 else 'æ— '}")

            db = self.db()

            # å¯¼å…¥SystemLogæ¨¡å‹
            from src.models.logs import SystemLog
            from datetime import datetime

            # æ‰¹é‡ä¿å­˜æ—¥å¿—ï¼ˆå¢é‡ä¿å­˜ï¼Œé¿å…é‡å¤ï¼‰
            saved_count = 0
            for log_entry in logs_data:
                # ä½¿ç”¨ id æˆ– timestamp ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                log_id = log_entry.get('id')
                log_timestamp = log_entry.get('timestamp')

                # å¦‚æœæ²¡æœ‰ idï¼Œä½¿ç”¨ timestamp ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                if not log_id and log_timestamp:
                    log_id = f"{worker_id}-{log_timestamp}"

                if not log_id:
                    logger.warning(f"æ—¥å¿—ç¼ºå°‘idå’Œtimestampï¼Œè·³è¿‡: {log_entry}")
                    continue

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ—¥å¿—ï¼ˆé¿å…é‡å¤ä¿å­˜ï¼‰
                existing_log = db.query(SystemLog).filter(
                    SystemLog.request_id == log_id,
                    SystemLog.worker_id == worker_id
                ).first()

                if existing_log:
                    continue  # è·³è¿‡å·²å­˜åœ¨çš„æ—¥å¿—

                # è·å–æ—¥å¿—æ•°æ®
                log_data = log_entry.get('data', {})

                # å¤„ç†IPåœ°å€å­—æ®µï¼ˆWorkerå¯èƒ½ä½¿ç”¨ipæˆ–source_ipï¼‰
                ip_address = log_data.get('ip') or log_data.get('source_ip')

                # å¤„ç†User-Agentå­—æ®µï¼ˆWorkerå¯èƒ½ä½¿ç”¨userAgentæˆ–user_agentï¼‰
                user_agent = log_data.get('userAgent') or log_data.get('user_agent')

                # è½¬æ¢æ—¶é—´æˆ³ä¸º datetimeï¼ˆå¦‚æœæ˜¯æ¯«ç§’æ—¶é—´æˆ³ï¼‰
                created_at = None
                if log_timestamp:
                    try:
                        # å‡è®¾æ—¶é—´æˆ³æ˜¯æ¯«ç§’
                        created_at = datetime.fromtimestamp(log_timestamp / 1000)
                    except Exception as e:
                        logger.warning(f"è½¬æ¢æ—¶é—´æˆ³å¤±è´¥: {e}")

                system_log = SystemLog(
                    worker_id=worker_id,
                    level=log_entry.get('level', 'INFO').upper(),
                    message=log_entry.get('message', ''),
                    details=log_data,
                    category='worker_sync',
                    source=f'worker-{worker_id}',
                    request_id=log_id,
                    ip_address=ip_address,
                    user_agent=user_agent
                )

                # å¦‚æœæœ‰æ—¶é—´æˆ³ï¼Œè®¾ç½®åˆ›å»ºæ—¶é—´
                if created_at:
                    system_log.created_at = created_at

                db.add(system_log)
                saved_count += 1

            db.commit()
            db.close()

            logger.info(f"âœ… å¤„ç†Workeræ—¥å¿—æˆåŠŸ: {worker_id}, æ¥æ”¶{len(logs_data)}æ¡, æ–°å¢{saved_count}æ¡")
            return True

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Workeræ—¥å¿—å¤±è´¥: {e}")
            return False

    async def process_worker_stats(self, worker_id: str, stats_data: Dict[str, Any]) -> bool:
        """å¤„ç†Workeræ¨é€çš„ç»Ÿè®¡æ•°æ®"""
        try:
            # ä½¿ç”¨ç»Ÿè®¡æœåŠ¡è®°å½•æ•°æ®
            success = await self.stats_service.record_worker_stats(worker_id, stats_data)

            if success:
                logger.info(f"âœ… å¤„ç†Workerç»Ÿè®¡æ•°æ®æˆåŠŸ: {worker_id}")
            else:
                logger.error(f"âŒ å¤„ç†Workerç»Ÿè®¡æ•°æ®å¤±è´¥: {worker_id}")

            return success

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Workerç»Ÿè®¡æ•°æ®å¼‚å¸¸: {e}")
            return False

    async def process_worker_config_status(self, worker_id: str, config_status: Dict[str, Any]) -> bool:
        """å¤„ç†Workeré…ç½®çŠ¶æ€"""
        try:
            # è¿™é‡Œå¯ä»¥è®°å½•é…ç½®åŒæ­¥çŠ¶æ€
            logger.info(f"âœ… æ”¶åˆ°Workeré…ç½®çŠ¶æ€: {worker_id}")
            logger.debug(f"é…ç½®çŠ¶æ€è¯¦æƒ…: {config_status}")

            # å¯ä»¥åœ¨è¿™é‡Œä¿å­˜é…ç½®çŠ¶æ€åˆ°æ•°æ®åº“
            # æš‚æ—¶åªè®°å½•æ—¥å¿—
            return True

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Workeré…ç½®çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def process_worker_config(self, worker_id: str, config_data: Dict[str, Any]) -> bool:
        """å¤„ç†Workeræ¨é€çš„é…ç½®æ•°æ®"""
        try:
            from src.models.config import WorkerConfig

            logger.info(f"ğŸ“‹ å¤„ç†Worker {worker_id} çš„é…ç½®æ•°æ®")

            db = self.db()

            # æŸ¥æ‰¾æˆ–åˆ›å»ºé…ç½®è®°å½•
            worker_config = db.query(WorkerConfig).filter(
                WorkerConfig.worker_id == worker_id
            ).first()

            if not worker_config:
                worker_config = WorkerConfig(worker_id=worker_id)

            # æ›´æ–°é…ç½®æ•°æ®
            worker_config.ua_configs = config_data.get("ua_configs", {})
            worker_config.ip_blacklist = config_data.get("ip_blacklist", [])
            worker_config.secret_usage = config_data.get("secret_usage", {})
            worker_config.last_update = config_data.get("last_update", 0)

            db.add(worker_config)
            db.commit()
            db.close()

            logger.info(f"âœ… Workeré…ç½®æ•°æ®ä¿å­˜æˆåŠŸ: {worker_id}")
            return True

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Workeré…ç½®æ•°æ®å¤±è´¥: {e}")
            return False

    async def process_worker_request_stats(self, worker_id: str, stats_data: Dict[str, Any]) -> bool:
        """å¤„ç†Workeræ¨é€çš„IPè¯·æ±‚ç»Ÿè®¡æ•°æ®"""
        try:
            from src.models.stats import IPRequestStats, RequestStats
            from datetime import datetime

            logger.info(f"ğŸ“Š å¤„ç†Worker {worker_id} çš„IPè¯·æ±‚ç»Ÿè®¡æ•°æ®")
            logger.debug(f"ğŸ“Š æ¥æ”¶åˆ°çš„ç»Ÿè®¡æ•°æ®: {stats_data}")

            db = self.db()

            # è·å–ç»Ÿè®¡æ•°æ®
            by_ip = stats_data.get("by_ip", {})
            total_requests = stats_data.get("total_requests", 0)

            logger.info(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {total_requests}")
            logger.info(f"ğŸ“Š by_ipæ•°æ®ç±»å‹: {type(by_ip)}, æ•°æ®é•¿åº¦: {len(by_ip) if isinstance(by_ip, dict) else 'N/A'}")
            current_hour = datetime.now().replace(minute=0, second=0, microsecond=0)

            # æ›´æ–° RequestStats è¡¨çš„æ€»è¯·æ±‚æ•°ï¼ˆç”¨äºä»ªè¡¨ç›˜ç»Ÿè®¡ï¼‰
            request_stats = db.query(RequestStats).filter(
                RequestStats.worker_id == worker_id,
                RequestStats.date_hour == current_hour
            ).first()

            if not request_stats:
                request_stats = RequestStats(
                    worker_id=worker_id,
                    date_hour=current_hour
                )
                db.add(request_stats)

            # æ›´æ–°æ€»è¯·æ±‚æ•°å’Œæ´»è·ƒIPæ•°
            request_stats.total_requests = total_requests
            request_stats.active_ips_count = len(by_ip)

            # è®¡ç®—è¿è§„æ€»æ•°
            total_violations = sum(ip_stats.get("violations", 0) for ip_stats in by_ip.values())
            request_stats.blocked_requests = total_violations

            # è®¡ç®—æˆåŠŸè¯·æ±‚æ•°ï¼ˆæ€»è¯·æ±‚ - è¿è§„ï¼‰
            request_stats.successful_requests = max(0, total_requests - total_violations)

            logger.info(f"ğŸ“Š æ›´æ–°RequestStats: æ€»è¯·æ±‚={total_requests}, æ´»è·ƒIP={len(by_ip)}, è¿è§„={total_violations}")

            # æ‰¹é‡ä¿å­˜IPè¯·æ±‚ç»Ÿè®¡
            saved_count = 0
            for ip_address, ip_stats in by_ip.items():
                try:
                    # æŸ¥æ‰¾æˆ–åˆ›å»ºIPç»Ÿè®¡è®°å½•
                    ip_request_stat = db.query(IPRequestStats).filter(
                        IPRequestStats.worker_id == worker_id,
                        IPRequestStats.ip_address == ip_address,
                        IPRequestStats.date_hour == current_hour
                    ).first()

                    if not ip_request_stat:
                        ip_request_stat = IPRequestStats(
                            worker_id=worker_id,
                            ip_address=ip_address,
                            date_hour=current_hour
                        )

                    # æ›´æ–°ç»Ÿè®¡æ•°æ®
                    ip_request_stat.total_count = ip_stats.get("total_count", 0)
                    ip_request_stat.violations = ip_stats.get("violations", 0)
                    ip_request_stat.paths = ip_stats.get("paths", {})

                    db.add(ip_request_stat)
                    saved_count += 1

                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜IP {ip_address} çš„ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
                    continue

            db.commit()
            db.close()

            logger.info(f"âœ… Worker IPè¯·æ±‚ç»Ÿè®¡æ•°æ®ä¿å­˜æˆåŠŸ: {worker_id}, å…±ä¿å­˜ {saved_count} æ¡IPç»Ÿè®¡")
            return True

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Worker IPè¯·æ±‚ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            return False
    
    async def query_worker_logs(self, worker_id: str = None, limit: int = 100) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢Workeræ¨é€çš„æ—¥å¿—æ•°æ®"""
        try:
            from src.models.logs import SystemLog

            db = self.db()

            # æ„å»ºæŸ¥è¯¢
            query = db.query(SystemLog).filter(SystemLog.category == 'worker_sync')

            if worker_id:
                query = query.filter(SystemLog.worker_id == worker_id)

            # æŒ‰æ—¶é—´å€’åºï¼Œè·å–æœ€æ–°çš„æ—¥å¿—
            logs = query.order_by(SystemLog.created_at.desc()).limit(limit).all()

            db.close()

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            result = []
            for log in logs:
                result.append({
                    "id": log.id,
                    "worker_id": log.worker_id,
                    "level": log.level,
                    "message": log.message,
                    "timestamp": int(log.created_at.timestamp() * 1000) if log.created_at else 0,
                    "data": log.details or {}
                })

            logger.info(f"âœ… æŸ¥è¯¢Worker {worker_id} çš„æ—¥å¿—æˆåŠŸï¼Œå…± {len(result)} æ¡")
            return result

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢Workeræ—¥å¿—å¤±è´¥: {e}")
            return []

    async def query_worker_request_stats(self, worker_id: str = None, limit: int = 100) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢Workeræ¨é€çš„ IP è¯·æ±‚ç»Ÿè®¡æ•°æ®"""
        try:
            from src.models.stats import IPRequestStats

            db = self.db()

            # æ„å»ºæŸ¥è¯¢
            query = db.query(IPRequestStats)

            if worker_id:
                query = query.filter(IPRequestStats.worker_id == worker_id)

            # æŒ‰æ—¶é—´å€’åºï¼Œè·å–æœ€æ–°çš„ç»Ÿè®¡
            stats = query.order_by(IPRequestStats.date_hour.desc()).limit(limit).all()

            db.close()

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            result = []
            for stat in stats:
                result.append({
                    "id": stat.id,
                    "worker_id": stat.worker_id,
                    "ip_address": stat.ip_address,
                    "total_count": stat.total_count,
                    "violations": stat.violations,
                    "paths": stat.paths or {},
                    "date_hour": stat.date_hour.isoformat() if stat.date_hour else None
                })

            logger.info(f"âœ… æŸ¥è¯¢Worker {worker_id} çš„IPè¯·æ±‚ç»Ÿè®¡æˆåŠŸï¼Œå…± {len(result)} æ¡")
            return result

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢Worker IPè¯·æ±‚ç»Ÿè®¡å¤±è´¥: {e}")
            return []

    async def get_worker_health_status(self, worker_endpoint: str) -> Dict[str, Any]:
        """è·å–Workerå¥åº·çŠ¶æ€"""
        try:
            async with httpx.AsyncClient(**self.client_config) as client:
                health_url = f"{worker_endpoint.rstrip('/')}/health"

                # è·å–APIå¯†é’¥
                from src.services.config_manager import config_manager
                api_key = config_manager.get_data_center_api_key()

                # æ„å»ºè¯·æ±‚å¤´
                headers = {"User-Agent": "DataCenter-Health/1.0"}
                if api_key:
                    headers["X-API-Key"] = api_key

                response = await client.get(health_url, headers=headers)

                if response.status_code == 200:
                    return {
                        "status": "healthy",
                        "endpoint": worker_endpoint,
                        "response_time": response.elapsed.total_seconds(),
                        "data": response.json()
                    }
                else:
                    return {
                        "status": "unhealthy",
                        "endpoint": worker_endpoint,
                        "error": f"HTTP {response.status_code}"
                    }

        except Exception as e:
            return {
                "status": "error",
                "endpoint": worker_endpoint,
                "error": str(e)
            }
